{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercises in Novelty and Outlier Detection (Exercise Solutions)\n",
    "In this final section, we’ll engage in practical exercises that involve detecting, evaluating, and handling anomalies in real-world datasets. These exercises are designed to reinforce the concepts introduced throughout the chapter—ranging from model selection to evaluation and strategy implementation. By the end of this section, you’ll have direct experience working with a variety of detection methods and be better equipped to select and fine-tune them based on your data and goals.\n",
    "\n",
    "### Exercise 1: Applying Isolation Forest to a Real-World Dataset\n",
    "In this exercise, we’ll detect outliers in a credit card transaction dataset using the Isolation Forest algorithm.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate synthetic data with inliers and outliers\n",
    "X_inliers, _ = make_blobs(n_samples=300, centers=[[0, 0]], cluster_std=0.6, random_state=2024)\n",
    "X_outliers = np.random.uniform(low=-6, high=6, size=(30, 2))\n",
    "X = np.vstack([X_inliers, X_outliers])\n",
    "y_true = np.array([0] * len(X_inliers) + [1] * len(X_outliers))\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply Isolation Forest\n",
    "model = IsolationForest(contamination=0.09, random_state=2024)\n",
    "model.fit(X_scaled)\n",
    "y_pred = model.predict(X_scaled)\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the results\n",
    "print(\"Exercise 1 Results:\")\n",
    "\n",
    "# Print classification report as a styled DataFrame\n",
    "report = classification_report(y_true, y_pred_binary, output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "styled_report = (report\n",
    "    .style\n",
    "    .background_gradient(cmap='Blues', subset=['precision', 'recall', 'f1-score'])\n",
    "    .format({\n",
    "        'precision': '{:.3f}',\n",
    "        'recall': '{:.3f}',\n",
    "        'f1-score': '{:.3f}',\n",
    "        'support': '{:.0f}'\n",
    "    })\n",
    ")\n",
    "display(styled_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Using LOF on a Network Intrusion Dataset\n",
    "In this task, we simulate an imbalanced network-like dataset with several clusters and injected noise. You'll apply the Local Outlier Factor algorithm to identify low-density regions where anomalous behavior might occur. Finally, you'll evaluate model performance using a confusion matrix and classification metrics.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate clustered data with synthetic noise\n",
    "X_clustered, _ = make_blobs(n_samples=400, centers=[[0, 0], [5, 5]], cluster_std=[0.5, 1.5], random_state=2024)\n",
    "X_noise = np.random.uniform(low=-6, high=10, size=(20, 2))\n",
    "X_combined = np.vstack([X_clustered, X_noise])\n",
    "y_combined = np.array([0] * 400 + [1] * 20)\n",
    "\n",
    "# Scale the data\n",
    "X_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# Apply Local Outlier Factor\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "y_pred = lof.fit_predict(X_scaled)\n",
    "y_pred_binary = np.where(y_pred == 1, 0, 1)\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(\"\\nExercise 2 Results:\")\n",
    "cm = confusion_matrix(y_combined, y_pred_binary)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Predicted Inlier', 'Predicted Outlier'],\n",
    "            yticklabels=['True Inlier', 'True Outlier'])\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "report = classification_report(y_combined, y_pred_binary, output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "styled_report = (report\n",
    "    .style\n",
    "    .background_gradient(cmap='Blues', subset=['precision', 'recall', 'f1-score'])\n",
    "    .format({\n",
    "        'precision': '{:.3f}',\n",
    "        'recall': '{:.3f}',\n",
    "        'f1-score': '{:.3f}',\n",
    "        'support': '{:.0f}'\n",
    "    })\n",
    ")\n",
    "display(styled_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: One-Class SVM for Manufacturing Sensor Data\n",
    "This exercise demonstrates novelty detection in a simulated manufacturing environment. You’ll train a model only on normal operational data, then use it to detect novel observations from a mix of normal and abnormal test data. Finally, you’ll visualize the inliers and detected novelties in 2D feature space.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate normal and novel data\n",
    "X_normal = np.random.normal(loc=0.0, scale=0.5, size=(300, 2))\n",
    "X_novelty = np.random.uniform(low=-4, high=4, size=(30, 2))\n",
    "X_train, X_test = train_test_split(X_normal, test_size=0.2, random_state=2024)\n",
    "X_eval = np.vstack([X_test, X_novelty])\n",
    "\n",
    "# Fit One-Class SVM on normal data\n",
    "svm_model = OneClassSVM(kernel='rbf', gamma='scale', nu=0.05)\n",
    "svm_model.fit(X_train)\n",
    "y_pred = svm_model.predict(X_eval)\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_eval[y_pred == 1][:, 0], X_eval[y_pred == 1][:, 1], color='blue', label='Inliers', alpha=0.6)\n",
    "plt.scatter(X_eval[y_pred == -1][:, 0], X_eval[y_pred == -1][:, 1], color='red', label='Detected Novelties')\n",
    "plt.title(\"Novelty Detection with One-Class SVM\")\n",
    "plt.xlabel(\"Sensor 1\")\n",
    "plt.ylabel(\"Sensor 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
