{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercises in Cross-Validation and Evaluation (Exercise Solutions)\n",
    "In this final section, we’ll engage in practical exercises that involve building, tuning, and evaluating models using cross-validation and performance metrics. These exercises are designed to reinforce the concepts explored throughout the chapter, including model selection, hyperparameter tuning, and generalization evaluation. By completing these exercises, we’ll solidify our understanding of how to effectively assess model performance and select the best model for real-world applications.\n",
    "\n",
    "## Exercise 1: Cross-Validating a Logistic Regression Model\n",
    "We’ll evaluate a logistic regression classifier using k-fold cross-validation and report multiple metrics.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Load the dataset\n",
    "X, y = make_classification(n_samples=500, n_features=10, random_state=2024)\n",
    "\n",
    "# Cross-validate and collect metrics\n",
    "model = LogisticRegression()\n",
    "results = cross_validate(model, X, y, cv=5, scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "\n",
    "for metric in [\"test_accuracy\", \"test_precision\", \"test_recall\", \"test_f1\"]:\n",
    "    print(f\"{metric}: {results[metric].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Tuning Hyperparameters with Grid Search\n",
    "We’ll perform hyperparameter tuning using GridSearchCV and compare the results.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load and split the dataset\n",
    "X, y = make_classification(n_samples=500, n_features=10, random_state=2024)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2024)\n",
    "\n",
    "# Perform grid search\n",
    "param_grid = {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Assessing Model Generalization with Learning and Validation Curves\n",
    "We’ll use learning_curve and validation_curve to visualize how model performance varies with training size and model complexity.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "\n",
    "# Plot the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    LogisticRegression(), X, y, cv=5, scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 5), random_state=2024)\n",
    "\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Training\")\n",
    "plt.plot(train_sizes, test_scores.mean(axis=1), label=\"Validation\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the validation curve\n",
    "param_range = np.logspace(-3, 2, 6)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    LogisticRegression(), X, y, param_name=\"C\", param_range=param_range,\n",
    "    cv=5, scoring='accuracy')\n",
    "\n",
    "plt.semilogx(param_range, train_scores.mean(axis=1), label=\"Training\")\n",
    "plt.semilogx(param_range, test_scores.mean(axis=1), label=\"Validation\")\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"C (Inverse Regularization Strength)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
