{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercises with Clustering Models (Exercise Solutions)\n",
    "In this final section, readers will engage in practical exercises that involve building, tuning, and evaluating clustering models on real-world datasets. These exercises are designed to reinforce the concepts learned throughout the chapter and demonstrate how to effectively apply clustering techniques in various scenarios. By the end of this section, readers will have hands-on experience that they can leverage in their own ML projects.\n",
    "\n",
    "## Exercise 1: Clustering with K-Means on the Iris Dataset\n",
    "In this example, weâ€™ll apply K-Means clustering to the well-known Iris dataset and evaluate the results using multiple metrics.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "# Create and Train the KMeans Model\n",
    "kmeans = KMeans(n_clusters=3, random_state=2024)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# Evaluate the Clustering\n",
    "sil_score = silhouette_score(X, y_kmeans)\n",
    "ari = adjusted_rand_score(y_true, y_kmeans)\n",
    "\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "print(f\"Adjusted Rand Index: {ari:.3f}\")\n",
    "\n",
    "# Visualize the Cluster Assignments (PCA Projection)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_pca = PCA(n_components=2).fit_transform(X)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_kmeans, cmap='viridis', s=50)\n",
    "plt.title(\"K-Means Clustering on Iris Dataset\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Comparing DBSCAN and K-Means on Moons Data\n",
    "This exercise demonstrates how DBSCAN can outperform K-Means on data with non-convex shapes.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and Scale the Dataset\n",
    "X, _ = make_moons(n_samples=300, noise=0.1, random_state=2024)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Apply KMeans and DBSCAN\n",
    "kmeans = KMeans(n_clusters=2, random_state=2024)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
    "y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "# Visualize the Clustering Results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.scatter(X[:, 0], X[:, 1], c=y_kmeans, cmap='viridis', s=50)\n",
    "ax1.set_title(\"K-Means Clustering\")\n",
    "\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=y_dbscan, cmap='plasma', s=50)\n",
    "ax2.set_title(\"DBSCAN Clustering\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Clustering High-Dimensional Data with PCA + GMM\n",
    "This exercise combines dimensionality reduction with a probabilistic clustering approach using Gaussian Mixture Models.\n",
    "\n",
    "### Implementation Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and Preprocess the Dataset\n",
    "data = load_wine()\n",
    "X = StandardScaler().fit_transform(data.data)\n",
    "\n",
    "# Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Fit Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=3, random_state=2024)\n",
    "y_gmm = gmm.fit_predict(X_pca)\n",
    "\n",
    "# Visualize the Clustered Output\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_gmm, cmap='viridis', s=50)\n",
    "plt.title(\"GMM Clustering with PCA on Wine Dataset\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
